---
title: Analysing Data from Files
teaching: 20
exercises: 0
questions:
- "How can I read data from, and write data to, a file?"
- "How can I do the same operations on many different files?"
objectives:
- "Use a `for` loop to read a file line-by-line"
- "Write functions to process file lines"
- "Use a library function to get a list of filenames that match a wildcard pattern."
- "Write a `for` loop to process multiple files."
keypoints:
- "Use `with open('my_file.txt') as f:` to open files"
- "Break lines into fields using `f.readline().split()`"
- "Use `glob.glob(pattern)` to create a list of files whose names match a pattern."
- "Use `*` in a pattern to match zero or more characters, and `?` to match any single character."
---

## Reading files

Reading files in python uses `for` loops. As a refresher, here is a simple `for` loop in Python:

~~~
for letter in 'ABCDEFGHIJ':
    print(letter)
~~~
{: .language-python}

> ## For loop practice
> Write a `for` loop that generates this image:
>
> .
>
> ..
>
> ...
>
> ....
>
> .....
{: .challenge}

Working with files is a two-step process. We first need to 'open' the file. Then, we can 'read' it line by line. 
There is some special syntax for opening files in Python. Behind the scenes, this special sytnax makes sure that the file is
closed again when we are done with it, and that the working memory it occupies becomes freed up for use again. This is the 
general recipe for reading a file:

~~~
with open('my_file') as f:
    for line in f:
        print(line)
~~~
{: .language-python}

Try it out! `my_file` is the *path* to the file you want to open. 

> ## Open a fastq file
> Fill in the blanks below to open and print the contents of your sample.fastq file
> ~~~
> with open('__________/sample.fastq') as f:
>     for line in ___:
>         print(____)
> ~~~
> {: .language-python}
{: .challenge}

There is nothing special about `f` or `line`, we can use any legal variable names here. This should also work:

~~~
with open('afds/py_scripts/data/sample.fastq') as fluffy:
    for unicorn in fluffy:
        print(unicorn)
~~~
{: .language-python}

## Processing file contents

So, we can read and print the contents of a file. What else can we do? Try this:

~~~
with open('afds/py_scripts/data/sample.fastq') as f:
    for line in f:
        print(type(line))
~~~
{: .language-python}

So, lines are read in as strings, which means we can perform any string operations on them.

What does this program do?
~~~
with open('afds/py_scripts/data/sample.fastq') as f:
    for line in f:
        if line[0] == '@'
            line.split(' ')
~~~
{: .language-python}

> ## Parsing data
> Modify the program in the cell above to just print a list of the machine/lane/flowcell coordinate data.
>
> Your expected output is:
> ~~~
> HWI-EAS216:4:1:0:1752
> HWI-EAS216:4:1:0:963
> HWI-EAS216:4:1:0:554
> HWI-EAS216:4:1:0:1229
> HWI-EAS216:4:1:0:475
> HWI-EAS216:4:1:0:834
> HWI-EAS216:4:1:0:1203
> HWI-EAS216:4:1:0:1123
> HWI-EAS216:4:1:0:1642
> HWI-EAS216:4:1:0:603
> HWI-EAS216:4:1:0:904
> HWI-EAS216:4:1:0:1572
> HWI-EAS216:4:1:0:1713
> ~~~
> {: .output}
>
> Challenge: further modify the program to print out *only* the coordinates. 
> Expected output:
> ~~~
> 0 1752
> 0 963
> 0 554
> 0 1229
> 0 475
> 0 834
> 0 1203
> 0 1123
> 0 1642
> 0 603
> 0 904
> 0 1572
> 0 1713
> ~~~
> {: .output}
{: .challenge}

Last week we spent some time extracting meta data from read headers in files. As you can see now, this is quite an easy task in Python!

## Writing to files

We now know how to read a file in Python and work with it line by line. We also know how to process these lines as strings, and extract the parts that we want. But how do we save this as output to a new file? 

Writing to a file uses the same `with open('my_file') as f` notation:

~~~
acrostic = 'Perhaps You Thought Hackers Outnumber Nerds'
with open('poetry.txt', 'w') as f:
    for word in acrostic:
        f.write(word+'\n')
~~~
{: .language-python}

Here, we have provided the **optional** argument `w` to the `open` function, which tells python we want to bring a 
new file into existence and write content into it. Warning: if you specify a file that already exists, and open it in 'write' 
mode using the `w` optional argument, your original file will be overwritten! By default, if you don't specify an argument, 
Python will open a file in read only, or `r` mode. There is a third mode, `a`. What does this do?

> ## Write to a file
> Fill in the blanks to write some code that splits read header information into relevant fields and saves the output as
> a nicely formated tab-delimited text file.
> ~~~
> with open('____/metadata.tsv', ___ ) as out_file:
>     out_file.write('machine', 'lane', 'tile', 'x-coord', 'y-coord', sep='___')
>     with open('_____/sample.fastq') as in_file:
>         for line in in_file:
>              seq_data = line.split()[__]
>              parts = seq_data._____(__)
>              out_file.write(_______)
> ~~~
> {: .language-python}
{: .challenge}
We now have almost everything we need to process all our data files.
The only thing that's missing is a library with a rather unpleasant name:

~~~
import glob
~~~
{: .language-python}

The `glob` library contains a function, also called `glob`,
that finds files and directories whose names match a pattern.
We provide those patterns as strings:
the character `*` matches zero or more characters,
while `?` matches any one character.
We can use this to get the names of all the CSV files in the current directory:

~~~
print(glob.glob('inflammation*.csv'))
~~~
{: .language-python}

~~~
['inflammation-05.csv', 'inflammation-11.csv', 'inflammation-12.csv', 'inflammation-08.csv',
'inflammation-03.csv', 'inflammation-06.csv', 'inflammation-09.csv', 'inflammation-07.csv',
'inflammation-10.csv', 'inflammation-02.csv', 'inflammation-04.csv', 'inflammation-01.csv']
~~~
{: .output}

As these examples show,
`glob.glob`'s result is a list of file and directory paths in arbitrary order.
This means we can loop over it
to do something with each filename in turn.
In our case,
the "something" we want to do is generate a set of plots for each file in our inflammation dataset.
If we want to start by analyzing just the first three files in alphabetical order, we can use the
`sorted` built-in function to generate a new sorted list from the `glob.glob` output:

~~~
import numpy
import matplotlib.pyplot

filenames = sorted(glob.glob('inflammation*.csv'))
filenames = filenames[0:3]
for f in filenames:
    print(f)

    data = numpy.loadtxt(fname=f, delimiter=',')

    fig = matplotlib.pyplot.figure(figsize=(10.0, 3.0))

    axes1 = fig.add_subplot(1, 3, 1)
    axes2 = fig.add_subplot(1, 3, 2)
    axes3 = fig.add_subplot(1, 3, 3)

    axes1.set_ylabel('average')
    axes1.plot(numpy.mean(data, axis=0))

    axes2.set_ylabel('max')
    axes2.plot(numpy.max(data, axis=0))

    axes3.set_ylabel('min')
    axes3.plot(numpy.min(data, axis=0))

    fig.tight_layout()
    matplotlib.pyplot.show()
~~~
{: .language-python}

~~~
inflammation-01.csv
~~~
{: .output}

![Analysis of inflammation-01.csv](../fig/03-loop_49_1.png)

~~~
inflammation-02.csv
~~~
{: .output}

![Analysis of inflammation-02.csv](../fig/03-loop_49_3.png)

~~~
inflammation-03.csv
~~~
{: .output}

![Analysis of inflammation-03.csv](../fig/03-loop_49_5.png)

Sure enough,
the maxima of the first two data sets show exactly the same ramp as the first,
and their minima show the same staircase structure;
a different situation has been revealed in the third dataset,
where the maxima are a bit less regular, but the minima are consistently zero.

> ## Plotting Differences
>
> Plot the difference between the average of the first dataset
> and the average of the second dataset,
> i.e., the difference between the leftmost plot of the first two figures.
>
> > ## Solution
> > ~~~
> > import glob
> > import numpy
> > import matplotlib.pyplot
> >
> > filenames = sorted(glob.glob('inflammation*.csv'))
> >
> > data0 = numpy.loadtxt(fname=filenames[0], delimiter=',')
> > data1 = numpy.loadtxt(fname=filenames[1], delimiter=',')
> >
> > fig = matplotlib.pyplot.figure(figsize=(10.0, 3.0))
> >
> > matplotlib.pyplot.ylabel('Difference in average')
> > matplotlib.pyplot.plot(data0.mean(axis=0) - data1.mean(axis=0))
> >
> > fig.tight_layout()
> > matplotlib.pyplot.show()
> > ~~~
> > {: .language-python}
> {: .solution}
{: .challenge}

> ## Generate Composite Statistics
>
> Use each of the files once to generate a dataset containing values averaged over all patients:
>
> ~~~
> filenames = glob.glob('inflammation*.csv')
> composite_data = numpy.zeros((60,40))
> for f in filenames:
>     # sum each new file's data into composite_data as it's read
>     #
> # and then divide the composite_data by number of samples
> composite_data /= len(filenames)
> ~~~
> {: .language-python}
>
> Then use pyplot to generate average, max, and min for all patients.
>
> > ## Solution
> > ~~~
> > import glob
> > import numpy
> > import matplotlib.pyplot
> >
> > filenames = glob.glob('inflammation*.csv')
> > composite_data = numpy.zeros((60,40))
> >
> > for f in filenames:
> >     data = numpy.loadtxt(fname = f, delimiter=',')
> >     composite_data += data
> >
> > composite_data/=len(filenames)
> >
> > fig = matplotlib.pyplot.figure(figsize=(10.0, 3.0))
> >
> > axes1 = fig.add_subplot(1, 3, 1)
> > axes2 = fig.add_subplot(1, 3, 2)
> > axes3 = fig.add_subplot(1, 3, 3)
> >
> > axes1.set_ylabel('average')
> > axes1.plot(numpy.mean(composite_data, axis=0))
> >
> > axes2.set_ylabel('max')
> > axes2.plot(numpy.max(composite_data, axis=0))
> >
> > axes3.set_ylabel('min')
> > axes3.plot(numpy.min(composite_data, axis=0))
> >
> > fig.tight_layout()
> >
> > matplotlib.pyplot.show()
> > ~~~
> > {: .language-python}
>{: .solution}
{: .challenge}

{% include links.md %}
